{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Pytorch_from_scratch_Daniel_Godoy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rebvQqA1IZSm"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fuJ2sAqIh2Z"
      },
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueEtFu8AImCT"
      },
      "source": [
        "# Generate dataset\n",
        "x = np.random.rand(100,1) #create 100 rows and 1 column matrix with the values between 0 and 1\n",
        "y = 1 + 2*x + .1*np.random.randn(100,1) # generate y values --> add bias of 1, with the weight of 2 and standard deviation of 0.1 for the noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp6YyN91JMxF"
      },
      "source": [
        "# shuffle the data\n",
        "idx = np.arange(100)\n",
        "np.random.shuffle(idx)\n",
        "train_idx = idx[:80]\n",
        "val_idx = idx[80:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BY68ZSoJjwE"
      },
      "source": [
        "x_train = x[train_idx]\n",
        "y_train = y[train_idx]\n",
        "x_val = x[val_idx]\n",
        "y_val = y[val_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLFntrIUJr1q"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "QG8M7lZ9J-v9",
        "outputId": "8f14763e-9eab-438b-dd29-4c863e969437"
      },
      "source": [
        "plt.plot(x_train, y_train, '*')\n",
        "plt.plot(x_val, y_val, '*')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0dbadf1630>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxhodOdnKFWQ"
      },
      "source": [
        "# From the graph, it is obvious that the bias is close to 1 and the slope (weight/parameter) is 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNtQLbY6KZvL"
      },
      "source": [
        "# Lets derive the bias and weight values from the regular regression method as well as pytorch framework"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcc7cxvkK_-F",
        "outputId": "6a800636-9ee9-4e65-897d-bd35ed136248"
      },
      "source": [
        "# Linear regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(x_train, y_train)\n",
        "print('Weight:',lin_reg.coef_)\n",
        "print('Bias:',lin_reg.intercept_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weight: [[1.96896447]]\n",
            "Bias: [1.02354075]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mADx0AtKLR7k"
      },
      "source": [
        "# Linear regression calculates the weight and bias close to its real value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "claFSeO3LvvE",
        "outputId": "3f9899b2-86b9-45e2-fa2d-83929d0bcbd4"
      },
      "source": [
        "# Lets use Numpy library to find the weight and bias\n",
        "a = np.random.rand(1) # initialize random bias value\n",
        "b = np.random.rand(1) # initalize random weight value\n",
        "\n",
        "epochs = 1000\n",
        "lr = 1e-1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # prediction\n",
        "  yhat = a + b * x_train\n",
        "  # error\n",
        "  error = y_train - yhat\n",
        "  # loss\n",
        "  loss = (error**2).mean()\n",
        "  # calculate gradient\n",
        "  a_grad = -2 * error.mean()\n",
        "  b_grad = -2 * (x_train*error).mean()\n",
        "  # update parameter\n",
        "  a -= lr*a_grad\n",
        "  b -= lr*b_grad\n",
        "\n",
        "print(f'weight: {b} \\nbias: {a}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight: [1.9689642] \n",
            "bias: [1.02354089]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4S3ElHMN5Qk"
      },
      "source": [
        "# Linear regression and Numpy libraries provides the same weight and bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0NB6A_ROU9U"
      },
      "source": [
        "# Let do it with pytorch\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lid0i0x8O6FS"
      },
      "source": [
        "# select the device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79lW0dhbPqao",
        "outputId": "5f1b8df4-d6d4-4002-a00b-cebd9bef4728"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhvFvp-8OtYJ"
      },
      "source": [
        "# convert the numpy format data to tensor form\n",
        "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
        "x_val_tensor = torch.from_numpy(x_val).float().to(device)\n",
        "y_val_tensor = torch.from_numpy(y_val).float().to(device)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM7G3OEtQPb3"
      },
      "source": [
        "# model \n",
        "model = nn.Sequential(nn.Linear(1,1)).to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-eD7JETQqZc"
      },
      "source": [
        "# loss function\n",
        "loss_fn = nn.MSELoss(reduction='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4_b8W_6Q_LL"
      },
      "source": [
        "# set optimizer\n",
        "lr = 1e-1\n",
        "opt = optim.SGD(model.parameters(), lr = lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htYNy-G1Qi0N",
        "outputId": "04fbcdd2-06e3-41ad-f54f-295a6e32a645"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  yhat = model(x_train_tensor)\n",
        "  loss = loss_fn(y_train_tensor, yhat)\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "  opt.zero_grad()\n",
        "print(model.state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('0.weight', tensor([[1.9690]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3ABIu1CSzts"
      },
      "source": [
        "# Pytorch found weight and bias...."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBOVykULTD_4"
      },
      "source": [
        "# So far we have learnt to use pytorch for linear model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgdBUtn8TLYh",
        "outputId": "61e11981-a6db-4d90-bbbc-944ac330750b"
      },
      "source": [
        "# Lets build a complete model with pytorch\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "# choose between CPU and GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# generate dataset\n",
        "x = np.random.rand(100,1)\n",
        "y = 1 + 2*x + 0.1*np.random.randn(100,1)\n",
        "\n",
        "# convert numpy data format to tensor format\n",
        "x_tensor = torch.from_numpy(x).float()\n",
        "y_tensor = torch.from_numpy(y).float()\n",
        "\n",
        "# create the tuples from x and y input data using TensorDataset to slice the dataset\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "train_dataset, val_dataset = random_split(dataset, [80,20])\n",
        "\n",
        "# Dataset is split into many batches using Dataloader\n",
        "train_dl = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "val_dl = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "# write a function to call train_step function which fit, cal loss, cal grad, opt param, and set param to zero and return loss\n",
        "def make_train_step(model, loss_fn, optimizer):\n",
        "  def train_step(x, y):\n",
        "    # set the model to train\n",
        "    model.train()\n",
        "    # predict\n",
        "    yhat = model(x)\n",
        "    # cal loss\n",
        "    loss = loss_fn(y, yhat)\n",
        "    # cal gradient\n",
        "    loss.backward()\n",
        "    # update param\n",
        "    optimizer.step()\n",
        "    # set grad to zero\n",
        "    optimizer.zero_grad()\n",
        "    return loss.item()\n",
        "  return train_step\n",
        "\n",
        "# provide learning rate and epoch \n",
        "lr = 1e-1\n",
        "epochs = 100\n",
        "\n",
        "# define model, loss function and optimizer\n",
        "model = nn.Sequential(nn.Linear(1,1)).to(device)\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "opt = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# instatiate make_train_step function to train_step\n",
        "train_step = make_train_step (model, loss_fn, opt)\n",
        "\n",
        "# create empty list to store training and validation loss of each epoch/training\n",
        "training_losses = []\n",
        "validataion_losses = []\n",
        "\n",
        "# iterate each epoch and fit the model with the training set\n",
        "for epoch in range(epochs):\n",
        "  # create batch_losses empty list to append the batch_loss of each batch\n",
        "  batch_losses = []\n",
        "  # iterate each batch from the train_dl\n",
        "  for x_batch, y_batch in train_dl:\n",
        "    # convert tensor format to gpu tensor format\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    # store the loss value of each batch in loss variable\n",
        "    loss = train_step(x_batch, y_batch)\n",
        "    # append the loss into batch_losses list\n",
        "    batch_losses.append(loss)\n",
        "\n",
        "  # take a mean of batch losses and append this particular epoch loss to training_losses\n",
        "  training_loss = np.mean(batch_losses)\n",
        "  training_losses.append(training_loss)\n",
        "\n",
        "  # evaluate the model with the validation dataset\n",
        "  # evaluation method doesn't require gradient\n",
        "  with torch.no_grad():\n",
        "    # create val_losses empty list to append the val_loss of each batch\n",
        "    val_losses = []\n",
        "    # iterate batches of validatation dataset\n",
        "    for x_val, y_val in val_dl:\n",
        "      # convert tensor format to gpu tensor format\n",
        "      x_val = x_val.to(device)\n",
        "      y_val = y_val.to(device)\n",
        "      # evaluate the model\n",
        "      model.eval()\n",
        "      # predict the model\n",
        "      yhat = model(x_val)\n",
        "      # calculate the loss\n",
        "      val_loss = loss_fn(y_val, yhat).item()\n",
        "      # append the loss to val_losses\n",
        "      val_losses.append(val_loss)\n",
        "    # append the mean value of losses each val_losses to validation_losses\n",
        "    validation_loss = np.mean(val_losses)\n",
        "    validataion_losses.append(validation_loss)\n",
        "\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'[{epoch+1}], training_loss: {training_loss:.3f}, validation_loss: {validation_loss:.3f} ')\n",
        "\n",
        "print(model.state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10], training_loss: 0.023, validation_loss: 0.026 \n",
            "[20], training_loss: 0.011, validation_loss: 0.010 \n",
            "[30], training_loss: 0.009, validation_loss: 0.008 \n",
            "[40], training_loss: 0.009, validation_loss: 0.007 \n",
            "[50], training_loss: 0.009, validation_loss: 0.007 \n",
            "[60], training_loss: 0.009, validation_loss: 0.007 \n",
            "[70], training_loss: 0.009, validation_loss: 0.007 \n",
            "[80], training_loss: 0.009, validation_loss: 0.007 \n",
            "[90], training_loss: 0.009, validation_loss: 0.007 \n",
            "[100], training_loss: 0.009, validation_loss: 0.007 \n",
            "OrderedDict([('0.weight', tensor([[1.9998]], device='cuda:0')), ('0.bias', tensor([1.0237], device='cuda:0'))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDRXbR4UlbKB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}